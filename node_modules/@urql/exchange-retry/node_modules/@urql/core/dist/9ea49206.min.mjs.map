{"version":3,"file":"9ea49206.min.mjs","sources":["../src/utils/error.ts","../src/utils/hash.ts","../src/utils/stringifyVariables.ts","../src/utils/request.ts","../src/utils/result.ts","../src/internal/fetchOptions.ts","../src/internal/fetchSource.ts"],"sourcesContent":["import { GraphQLError } from 'graphql';\n\nconst generateErrorMessage = (\n  networkErr?: Error,\n  graphQlErrs?: GraphQLError[]\n) => {\n  let error = '';\n  if (networkErr) return `[Network] ${networkErr.message}`;\n  if (graphQlErrs) {\n    for (const err of graphQlErrs) {\n      if (error) error += '\\n';\n      error += `[GraphQL] ${err.message}`;\n    }\n  }\n  return error;\n};\n\nconst rehydrateGraphQlError = (error: any): GraphQLError => {\n  if (typeof error === 'string') {\n    return new GraphQLError(error);\n  } else if (typeof error === 'object' && error.message) {\n    return new GraphQLError(\n      error.message,\n      error.nodes,\n      error.source,\n      error.positions,\n      error.path,\n      error,\n      error.extensions || {}\n    );\n  } else {\n    return error as any;\n  }\n};\n\n/** An error which can consist of GraphQL errors and Network errors. */\nexport class CombinedError extends Error {\n  public name: string;\n  public message: string;\n  public graphQLErrors: GraphQLError[];\n  public networkError?: Error;\n  public response?: any;\n\n  constructor(input: {\n    networkError?: Error;\n    graphQLErrors?: Array<string | Partial<GraphQLError> | Error>;\n    response?: any;\n  }) {\n    const normalizedGraphQLErrors = (input.graphQLErrors || []).map(\n      rehydrateGraphQlError\n    );\n    const message = generateErrorMessage(\n      input.networkError,\n      normalizedGraphQLErrors\n    );\n\n    super(message);\n\n    this.name = 'CombinedError';\n    this.message = message;\n    this.graphQLErrors = normalizedGraphQLErrors;\n    this.networkError = input.networkError;\n    this.response = input.response;\n  }\n\n  toString() {\n    return this.message;\n  }\n}\n","// When we have separate strings it's useful to run a progressive\n// version of djb2 where we pretend that we're still looping over\n// the same string\nexport const phash = (h: number, x: string): number => {\n  for (let i = 0, l = x.length | 0; i < l; i++)\n    h = (h << 5) + h + x.charCodeAt(i);\n  return h | 0;\n};\n\n// This is a djb2 hashing function\nexport const hash = (x: string): number => phash(5381 | 0, x) >>> 0;\n","const seen = new Set();\nconst cache = new WeakMap();\n\nconst stringify = (x: any): string => {\n  if (x === null || seen.has(x)) {\n    return 'null';\n  } else if (typeof x !== 'object') {\n    return JSON.stringify(x) || '';\n  } else if (x.toJSON) {\n    return stringify(x.toJSON());\n  } else if (Array.isArray(x)) {\n    let out = '[';\n    for (let value of x) {\n      if (out !== '[') out += ',';\n      value = stringify(value);\n      out += value.length > 0 ? value : 'null';\n    }\n\n    out += ']';\n    return out;\n  }\n\n  const keys = Object.keys(x).sort();\n  if (!keys.length && x.constructor && x.constructor !== Object) {\n    const key = cache.get(x) || Math.random().toString(36).slice(2);\n    cache.set(x, key);\n    return `{\"__key\":\"${key}\"}`;\n  }\n\n  seen.add(x);\n  let out = '{';\n  for (const key of keys) {\n    const value = stringify(x[key]);\n    if (value) {\n      if (out.length > 1) out += ',';\n      out += stringify(key) + ':' + value;\n    }\n  }\n\n  seen.delete(x);\n  out += '}';\n  return out;\n};\n\nexport const stringifyVariables = (x: any): string => {\n  seen.clear();\n  return stringify(x);\n};\n","import { TypedDocumentNode } from '@graphql-typed-document-node/core';\n\nimport {\n  Location,\n  DefinitionNode,\n  DocumentNode,\n  Kind,\n  parse,\n  print,\n} from 'graphql';\n\nimport { hash, phash } from './hash';\nimport { stringifyVariables } from './stringifyVariables';\nimport { AnyVariables, GraphQLRequest } from '../types';\n\ninterface WritableLocation {\n  loc: Location | undefined;\n}\n\nexport interface KeyedDocumentNode extends DocumentNode {\n  __key: number;\n}\n\nconst GRAPHQL_STRING_RE = /(\"{3}[\\s\\S]*\"{3}|\"(?:\\\\.|[^\"])*\")/g;\nconst REPLACE_CHAR_RE = /([\\s,]|#[^\\n\\r]+)+/g;\n\nconst replaceOutsideStrings = (str: string, idx: number) =>\n  idx % 2 === 0 ? str.replace(REPLACE_CHAR_RE, ' ').trim() : str;\n\nexport const stringifyDocument = (\n  node: string | DefinitionNode | DocumentNode\n): string => {\n  let str = (typeof node !== 'string'\n    ? (node.loc && node.loc.source.body) || print(node)\n    : node\n  )\n    .split(GRAPHQL_STRING_RE)\n    .map(replaceOutsideStrings)\n    .join('');\n\n  if (typeof node !== 'string') {\n    const operationName = 'definitions' in node && getOperationName(node);\n    if (operationName) {\n      str = `# ${operationName}\\n${str}`;\n    }\n\n    if (!node.loc) {\n      (node as WritableLocation).loc = {\n        start: 0,\n        end: str.length,\n        source: {\n          body: str,\n          name: 'gql',\n          locationOffset: { line: 1, column: 1 },\n        },\n      } as Location;\n    }\n  }\n\n  return str;\n};\n\nconst docs = new Map<number, KeyedDocumentNode>();\n\nexport const keyDocument = (q: string | DocumentNode): KeyedDocumentNode => {\n  let key: number;\n  let query: DocumentNode;\n  if (typeof q === 'string') {\n    key = hash(stringifyDocument(q));\n    query = docs.get(key) || parse(q, { noLocation: true });\n  } else {\n    key = (q as KeyedDocumentNode).__key || hash(stringifyDocument(q));\n    query = docs.get(key) || q;\n  }\n\n  // Add location information if it's missing\n  if (!query.loc) stringifyDocument(query);\n\n  (query as KeyedDocumentNode).__key = key;\n  docs.set(key, query as KeyedDocumentNode);\n  return query as KeyedDocumentNode;\n};\n\nexport const createRequest = <\n  Data = any,\n  Variables extends AnyVariables = AnyVariables\n>(\n  q: string | DocumentNode | TypedDocumentNode<Data, Variables>,\n  vars: Variables\n): GraphQLRequest<Data, Variables> => {\n  if (!vars) vars = {} as Variables;\n  const query = keyDocument(q);\n  return {\n    key: phash(query.__key, stringifyVariables(vars)) >>> 0,\n    query,\n    variables: vars as Variables,\n  };\n};\n\n/**\n * Finds the Name value from the OperationDefinition of a Document\n */\nexport const getOperationName = (query: DocumentNode): string | undefined => {\n  for (const node of query.definitions) {\n    if (node.kind === Kind.OPERATION_DEFINITION && node.name) {\n      return node.name.value;\n    }\n  }\n};\n\n/**\n * Finds the operation-type\n */\nexport const getOperationType = (query: DocumentNode): string | undefined => {\n  for (const node of query.definitions) {\n    if (node.kind === Kind.OPERATION_DEFINITION) {\n      return node.operation;\n    }\n  }\n};\n","import { ExecutionResult, Operation, OperationResult } from '../types';\nimport { CombinedError } from './error';\n\nexport const makeResult = (\n  operation: Operation,\n  result: ExecutionResult,\n  response?: any\n): OperationResult => {\n  if ((!('data' in result) && !('errors' in result)) || 'path' in result) {\n    throw new Error('No Content');\n  }\n\n  return {\n    operation,\n    data: result.data,\n    error: Array.isArray(result.errors)\n      ? new CombinedError({\n          graphQLErrors: result.errors,\n          response,\n        })\n      : undefined,\n    extensions:\n      (typeof result.extensions === 'object' && result.extensions) || undefined,\n    hasNext: !!result.hasNext,\n  };\n};\n\nexport const mergeResultPatch = (\n  prevResult: OperationResult,\n  patch: ExecutionResult,\n  response?: any\n): OperationResult => {\n  const result = { ...prevResult };\n  result.hasNext = !!patch.hasNext;\n\n  if (!('path' in patch)) {\n    if ('data' in patch) result.data = patch.data;\n    return result;\n  }\n\n  if (Array.isArray(patch.errors)) {\n    result.error = new CombinedError({\n      graphQLErrors: result.error\n        ? [...result.error.graphQLErrors, ...patch.errors]\n        : patch.errors,\n      response,\n    });\n  }\n\n  let part: Record<string, any> | Array<any> = (result.data = {\n    ...result.data,\n  });\n\n  let i = 0;\n  let prop: string | number;\n  while (i < patch.path.length) {\n    prop = patch.path[i++];\n    part = part[prop] = Array.isArray(part[prop])\n      ? [...part[prop]]\n      : { ...part[prop] };\n  }\n\n  Object.assign(part, patch.data);\n  return result;\n};\n\nexport const makeErrorResult = (\n  operation: Operation,\n  error: Error,\n  response?: any\n): OperationResult => ({\n  operation,\n  data: undefined,\n  error: new CombinedError({\n    networkError: error,\n    response,\n  }),\n  extensions: undefined,\n});\n","import { print } from 'graphql';\nimport { getOperationName, stringifyVariables } from '../utils';\nimport { AnyVariables, GraphQLRequest, Operation } from '../types';\n\nexport interface FetchBody {\n  query?: string;\n  operationName: string | undefined;\n  variables: undefined | Record<string, any>;\n  extensions: undefined | Record<string, any>;\n}\n\nexport function makeFetchBody<\n  Data = any,\n  Variables extends AnyVariables = AnyVariables\n>(request: Omit<GraphQLRequest<Data, Variables>, 'key'>): FetchBody {\n  return {\n    query: print(request.query),\n    operationName: getOperationName(request.query),\n    variables: request.variables || undefined,\n    extensions: undefined,\n  };\n}\n\nexport const makeFetchURL = (\n  operation: Operation,\n  body?: FetchBody\n): string => {\n  const useGETMethod =\n    operation.kind === 'query' && !!operation.context.preferGetMethod;\n  if (!useGETMethod || !body) return operation.context.url;\n\n  const url = new URL(operation.context.url);\n  const search = url.searchParams;\n  if (body.operationName) search.set('operationName', body.operationName);\n  if (body.query)\n    search.set('query', body.query.replace(/#[^\\n\\r]+/g, ' ').trim());\n  if (body.variables)\n    search.set('variables', stringifyVariables(body.variables));\n  if (body.extensions)\n    search.set('extensions', stringifyVariables(body.extensions));\n\n  const finalUrl = url.toString();\n  if (finalUrl.length > 2047) {\n    operation.context.preferGetMethod = false;\n    return operation.context.url;\n  }\n\n  return finalUrl;\n};\n\nexport const makeFetchOptions = (\n  operation: Operation,\n  body?: FetchBody\n): RequestInit => {\n  const useGETMethod =\n    operation.kind === 'query' && !!operation.context.preferGetMethod;\n  const headers: HeadersInit = {\n    accept: 'application/graphql+json, application/json',\n  };\n  if (!useGETMethod) headers['content-type'] = 'application/json';\n  const extraOptions =\n    (typeof operation.context.fetchOptions === 'function'\n      ? operation.context.fetchOptions()\n      : operation.context.fetchOptions) || {};\n  if (extraOptions.headers)\n    for (const key in extraOptions.headers)\n      headers[key.toLowerCase()] = extraOptions.headers[key];\n  return {\n    ...extraOptions,\n    body: !useGETMethod && body ? JSON.stringify(body) : undefined,\n    method: useGETMethod ? 'GET' : 'POST',\n    headers,\n  };\n};\n","import { Source, make } from 'wonka';\nimport { Operation, OperationResult } from '../types';\nimport { makeResult, makeErrorResult, mergeResultPatch } from '../utils';\n\nconst decoder = typeof TextDecoder !== 'undefined' ? new TextDecoder() : null;\nconst jsonHeaderRe = /content-type:[^\\r\\n]*application\\/json/i;\nconst boundaryHeaderRe = /boundary=\"?([^=\";]+)\"?/i;\n\ntype ChunkData = { done: false; value: Buffer | Uint8Array } | { done: true };\n\n// NOTE: We're avoiding referencing the `Buffer` global here to prevent\n// auto-polyfilling in Webpack\nconst toString = (input: Buffer | ArrayBuffer): string =>\n  input.constructor.name === 'Buffer'\n    ? (input as Buffer).toString()\n    : decoder!.decode(input as ArrayBuffer);\n\nexport const makeFetchSource = (\n  operation: Operation,\n  url: string,\n  fetchOptions: RequestInit\n): Source<OperationResult> => {\n  const maxStatus = fetchOptions.redirect === 'manual' ? 400 : 300;\n  const fetcher = operation.context.fetch;\n\n  return make<OperationResult>(({ next, complete }) => {\n    const abortController =\n      typeof AbortController !== 'undefined' ? new AbortController() : null;\n    if (abortController) {\n      fetchOptions.signal = abortController.signal;\n    }\n\n    let hasResults = false;\n    // DERIVATIVE: Copyright (c) 2021 Marais Rossouw <hi@marais.io>\n    // See: https://github.com/maraisr/meros/blob/219fe95/src/browser.ts\n    const executeIncrementalFetch = (\n      onResult: (result: OperationResult) => void,\n      operation: Operation,\n      response: Response\n    ): Promise<void> => {\n      // NOTE: Guarding against fetch polyfills here\n      const contentType =\n        (response.headers && response.headers.get('Content-Type')) || '';\n      if (/text\\//i.test(contentType)) {\n        return response.text().then(text => {\n          onResult(makeErrorResult(operation, new Error(text), response));\n        });\n      } else if (!/multipart\\/mixed/i.test(contentType)) {\n        return response.text().then(payload => {\n          onResult(makeResult(operation, JSON.parse(payload), response));\n        });\n      }\n\n      let boundary = '---';\n      const boundaryHeader = contentType.match(boundaryHeaderRe);\n      if (boundaryHeader) boundary = '--' + boundaryHeader[1];\n\n      let read: () => Promise<ChunkData>;\n      let cancel = () => {\n        /*noop*/\n      };\n      if (response[Symbol.asyncIterator]) {\n        const iterator = response[Symbol.asyncIterator]();\n        read = iterator.next.bind(iterator);\n      } else if ('body' in response && response.body) {\n        const reader = response.body.getReader();\n        cancel = () => reader.cancel();\n        read = () => reader.read();\n      } else {\n        throw new TypeError('Streaming requests unsupported');\n      }\n\n      let buffer = '';\n      let isPreamble = true;\n      let nextResult: OperationResult | null = null;\n      let prevResult: OperationResult | null = null;\n\n      function next(data: ChunkData): Promise<void> | void {\n        if (!data.done) {\n          const chunk = toString(data.value);\n          let boundaryIndex = chunk.indexOf(boundary);\n          if (boundaryIndex > -1) {\n            boundaryIndex += buffer.length;\n          } else {\n            boundaryIndex = buffer.indexOf(boundary);\n          }\n\n          buffer += chunk;\n          while (boundaryIndex > -1) {\n            const current = buffer.slice(0, boundaryIndex);\n            const next = buffer.slice(boundaryIndex + boundary.length);\n\n            if (isPreamble) {\n              isPreamble = false;\n            } else {\n              const headersEnd = current.indexOf('\\r\\n\\r\\n') + 4;\n              const headers = current.slice(0, headersEnd);\n              const body = current.slice(\n                headersEnd,\n                current.lastIndexOf('\\r\\n')\n              );\n\n              let payload: any;\n              if (jsonHeaderRe.test(headers)) {\n                try {\n                  payload = JSON.parse(body);\n                  nextResult = prevResult = prevResult\n                    ? mergeResultPatch(prevResult, payload, response)\n                    : makeResult(operation, payload, response);\n                } catch (_error) {}\n              }\n\n              if (next.slice(0, 2) === '--' || (payload && !payload.hasNext)) {\n                if (!prevResult)\n                  return onResult(makeResult(operation, {}, response));\n                break;\n              }\n            }\n\n            buffer = next;\n            boundaryIndex = buffer.indexOf(boundary);\n          }\n        } else {\n          hasResults = true;\n        }\n\n        if (nextResult) {\n          onResult(nextResult);\n          nextResult = null;\n        }\n\n        if (!data.done && (!prevResult || prevResult.hasNext)) {\n          return read().then(next);\n        }\n      }\n\n      return read().then(next).finally(cancel);\n    };\n\n    let ended = false;\n    let statusNotOk = false;\n    let response: Response;\n\n    Promise.resolve()\n      .then(() => {\n        if (ended) return;\n        return (fetcher || fetch)(url, fetchOptions);\n      })\n      .then((_response: Response | void) => {\n        if (!_response) return;\n        response = _response;\n        statusNotOk = response.status < 200 || response.status >= maxStatus;\n        return executeIncrementalFetch(next, operation, response);\n      })\n      .then(complete)\n      .catch((error: Error) => {\n        if (hasResults) {\n          throw error;\n        }\n\n        const result = makeErrorResult(\n          operation,\n          statusNotOk\n            ? response.statusText\n              ? new Error(response.statusText)\n              : error\n            : error,\n          response\n        );\n\n        next(result);\n        complete();\n      });\n\n    return () => {\n      ended = true;\n      if (abortController) {\n        abortController.abort();\n      }\n    };\n  });\n};\n"],"names":["rehydrateGraphQlError","error","GraphQLError","message","nodes","source","positions","path","extensions","CombinedError","Error","constructor","input","normalizedGraphQLErrors","graphQLErrors","map","networkErr","graphQlErrs","err","this","name","networkError","response","phash","h","x","i","l","length","charCodeAt","cache","WeakMap","seen","has","stringify","value","_out","out","get","Math","random","toString","slice","key","_value","_key","REPLACE_CHAR_RE","node","operationName","str","start","body","docs","Map","noLocation","hash","stringifyDocument","q","query","parse","__key","vars","variables","stringifyVariables","getOperationName","definitions","kind","Kind","OPERATION_DEFINITION","getOperationType","makeResult","operation","result","undefined","hasNext","errors","mergeResultPatch","prevResult","patch","part","isArray","data","prop","Array","makeErrorResult","makeFetchBody","request","print","url","context","searchParams","search","set","headers","accept","preferGetMethod","useGETMethod","extraOptions","TextDecoder","jsonHeaderRe","toLowerCase","fetchOptions","signal","maxStatus","redirect","test","contentType","hasResults","catch","Promise","resolve","then","ended","_response","complete","boundaryHeader","text","TypeError","iterator","Symbol","asyncIterator","buffer","boundaryIndex","nextResult","read","chunk","indexOf","boundary","payload","headersEnd","current","next","lastIndexOf","_error","onResult","_next","done","executeIncrementalFetch","statusNotOk","statusText"],"mappings":"oGAEA,IAeAA,EAAAC,GACE,iBAAAA,EACE,IAAAC,EAAAD,iCAEA,IAAAC,EAAAD,EAAAE,QAAAF,EAAAG,MAAAH,EAAAI,OAAAJ,EAAAK,UAAAL,EAAAM,KAAAN,EAAAA,EAAAO,YAAA,IAUAP,EAKJ,MAAAQ,UAAAC,MAOEC,YAAAC,GAKE,IAAAC,GAAAD,EAAAE,eAAA,IAAAC,IAAAf,KA9CJ,EAAAgB,EAAAC,cAKE,GAAAD,EAAgB,MAAA,aAAAA,EAAAb,UAChB,GAAAc,EACE,IAAA,IAAAC,KAAAD,EACEhB,aACAA,GAAA,aAAAiB,EAAAf,UAGJ,OAAAF,+BA4CEkB,KAAAC,KAAA,gBACAD,KAAAhB,QAAAA,EACAgB,KAAAL,cAAAD,EACAM,KAAAE,aAAAT,EAAAS,aACAF,KAAAG,SAAAV,EAAAU,yCC3DJ,IAAAC,EAAA,CAAAC,EAAAC,KACE,IAAA,IAAAC,EAAA,EAAAC,EAAA,EAAAF,EAAAG,OAAAF,EAAAC,EAAAD,IACEF,GAAAA,GAAA,GAAAA,EAAAC,EAAAI,WAAAH,kCCJJI,EAAA,IAAAC,wBAII,UAAAN,GAAAO,EAAAC,IAAAR,SACK,0DAGL,+EAKES,UAAAC,GAAA,KAEDC,IADCC,EAAAF,EAAAP,IACDA,OAAA,EAAAO,EAAA,OAIF,OADCC,uFAMAN,IAAAA,EAAAL,EAAAa,IAAAb,IAAAc,KAAAC,SAAAC,SAAA,IAAAC,MAAA,GAED,kBAAA,aAAAC,uDAOGC,yBAEDP,GAAAH,EAAAW,GAAA,IAAAD,GAjCL,mBAsCEP,EAAAA,WAKAL,EAAAE,QACFA,EAAAT,ICvBAqB,EAAA,yGAQEC,8IAWIC,IACDC,EAAA,KAAAD,MAAAC,aAIGC,EAAAA,aAEA7C,MAAAuB,OACEuB,OAAAF,CACA7B,KAAA6B,iDAvBV,OAAAA,GAoCEG,EAAA,IAAAC,UAEA,IAAAV,IAuBA,MArBE,iBAAAW,GAAAX,EAAAY,EAAAC,EAAAC,IACKC,EAAAN,EAAAd,IAAAK,IAAAgB,EAAAF,EAAA,CACLH,YAAA,wCASFI,OAAAF,EAAAE,GAhBFA,EAAAE,MAAAjB,aA0BEkB,GAGElB,EAAA,CAAAiB,EAAAA,eAEAE,IAAAA,IAAAD,UAZJlB,IAAApB,EAAAmC,EAAAE,MAAAG,EAAAF,MAAA,EAgBAH,sBAQGM,EAAAN,IALH,IAAA,IAAAX,KAAAW,EAAAO,YAQA,GAAAlB,EAAAmB,OAAAC,EAAAC,sBAAArB,EAAA3B,0BASAiD,EAAAX,+BCpHAY,GAAAA,EAAAA,OAAAC,EAAAH,qBAKE,OAAArB,EAAAyB,yGAYIC,CACFjE,YAEAkE,OAAAF,0CApBJ1D,cAAA0D,EAAAG,OAwBAC,kBAKEJ,EAAAhE,WAAA,iBAAAgE,EAAAhE,YAAAgE,EAAAhE,iBAAAiE,wBAKEG,EAAA,CAAAC,EAAAC,EAAAxD,KACD,IAAAkD,EAAA,IAAAK,0CAGC,kCAAAL,EAQFO,MAAAC,QAAAC,EAAAN,UAAAH,EAAAvE,MAAA,IAAAQ,EAAA,uEAKAyE,cASA,UANEH,EAAAP,EAAAS,KAAAE,IAAAH,EAAAD,MAGDrD,EAAA,EAGD8C,IAAAjE,KAAAqB,QAGFwD,EAAAA,EAvCAF,EAAAJ,EAAAvE,KAAAmB,MAuCA6C,MAAAA,QAAAQ,MAAA,IAAAA,EAAAG,IAAA,IAAAH,EAAAG,WAQI7D,OAAAA,OAAA0D,aARJK,EAAA,CAAAb,EAAAtE,EAAAqB,KAAA,aCvDA+D,UAAAA,eAKI3B,aAAAzD,EACA+C,aAEAxC,gBAAAiE,eAIJa,GAIE,MAAA,CAEA5B,MAAA6B,EAAAD,EAAAnC,0CAGAqC,kBAAAf,qBASA,OAAAF,EAAApB,KACA,kDAAAA,EAAA,OAAAoB,EAAAkB,QAAAD,IACEjB,UAAAkB,IAAAA,EAAAA,QAAAD,OACAA,EAAAE,aACDvC,EAAAH,eAAA2C,EAAAC,IAAA,gBAAAzC,EAAAH,gFAEDG,aAAAwC,EAAAC,IAAA,YAAA7B,EAAAZ,EAAAW,YAxBFX,EAAA3C,YAAAmF,EAAAC,IAAA,aAAA7B,EAAAZ,EAAA3C,qBA2BAiC,WAME,OAAAoD,EAAAjE,OAAA,MACEkE,EAAAL,QAAAM,iBAAA,EADFxB,EAAAkB,QAAAD,kBAaErC,IAAA6C,EAAA,UAAAA,EAAA9B,QAAAK,kFAIJyB,IAAAH,EAAA,gBAAA,0HCrEA,GAAAI,EAAAC,QAAAA,IAAA,IAAAvD,KAAAsD,EAAAJ,QACAM,EAAAA,EAAAC,eAAAH,EAAAJ,QAAAlD,GAMA,MAAA,IAAAsD,sCACAxD,OAAAuD,QAAArF,kJAiBM0F,EAAAC,CAAAA,EAAAd,EAAAa,KACD,IAAAE,EAAA,WAAAF,EAAAG,SAAA,IAAA,+HAaCH,EAAAI,OAAAC,EAAAJ,QAGE,IA8GAhF,EA9GAqF,aA6GDC,SAEGC,QAAAC,UAAAC,MAAA,KACD,IAAAC,2BAEDD,MAAAE,mBAWAC,EAAAD,2BA1HE1C,EAAAA,EAAAA,OAEH,IAAAmC,EAAApF,EAAAuE,SAAAvE,EAAAuE,QAAAvD,IAAA,iBAAA,kDAID6E,EAAA/B,EAAoBb,EAAA,IAAA7D,MAAA0G,GAAA9F,uHAMpB6F,IAGO7F,EAAAA,KAAAA,EAAA,iBAKL,KAAA+F,OAAAA,eAAA,CACD,IAAAC,EAAAhG,EAAAiG,OAAAC,gLAWG,IAAAC,EAAAC,MACE,EACDC,EAAM,KACLD,EAAAA,KAiEJ,OAAAE,IAAAb,8BAhBCJ,GAAA,8EA7CCe,EAAAG,EAAAC,QAAAC,GASI,SAPFL,GAAAD,EAAA7F,OAEA8F,EAAAD,EAAAK,QAAAC,eAUE,IAAAC,EAAAP,EAAA/E,MAAA,EAAAgF,KACAD,EAAAhB,MAAAZ,EAAAkC,EAAAnG,QAEIoG,GAAAA,YAKH,IAAAC,EAAAC,EAAAJ,QAAA,YAAA,iBAEDK,IAAAzF,MAAAuF,EAAAC,EAAAE,4BACEvD,EAGD,GAAAsB,EAAAM,KAAAZ,GACF,4CAGD6B,MAAAW,2CAIH,IAAAxD,EAAA,OAAAyD,EAAAhE,EAAAC,EAAA,GAAAjD,cAKAmG,EAAAc,qBAYLjH,GALEsG,oBAKFY,QAAA3D,GAAAA,EAAAH,2CAiCA+D,CAAAN,EAAA5D,EAAAjD,8BAEE,QAFF,IAAAkD,EAAAY,EAAAb,EAAAmE,GAAApH,EAAAqH,WAAA,IAAAjI,MAAAY,EAAAqH,YAAA1I,EAAAqB,QAOJ4F"}